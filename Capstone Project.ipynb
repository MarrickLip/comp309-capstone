{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP309 Capstone Project\n",
    "#### Marrick Lip, 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [0] Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 Get the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (19.3.1)\n",
      "Collecting tensorflow-gpu\n",
      "  Using cached https://files.pythonhosted.org/packages/25/44/47f0722aea081697143fbcf5d2aa60d1aee4aaacb5869aee2b568974777b/tensorflow_gpu-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl\n",
      "Requirement already satisfied: gast==0.2.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow-gpu) (0.2.2)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow-gpu) (3.9.2)\n",
      "Requirement already satisfied: astor>=0.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow-gpu) (0.8.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow-gpu) (0.1.7)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow-gpu) (1.0.8)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow-gpu) (1.1.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow-gpu) (0.33.6)\n",
      "Requirement already satisfied: tensorboard<2.1.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow-gpu) (2.0.0)\n",
      "Processing /home/ec2-user/.cache/pip/wheels/d7/de/2e/efa132238792efb6459a96e85916ef8597fcb3d2ae51590dfd/wrapt-1.11.2-cp36-cp36m-linux_x86_64.whl\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow-gpu) (1.17.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.1.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow-gpu) (2.0.1)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow-gpu) (0.8.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow-gpu) (3.1.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow-gpu) (1.24.3)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow-gpu) (1.12.0)\n",
      "Processing /home/ec2-user/.cache/pip/wheels/7c/06/54/bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6/termcolor-1.1.0-cp36-none-any.whl\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from protobuf>=3.6.1->tensorflow-gpu) (41.4.0)\n",
      "Requirement already satisfied: h5py in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from keras-applications>=1.0.8->tensorflow-gpu) (2.9.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (3.1.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (0.16.0)\n",
      "\u001b[31mERROR: fastai 1.0.55 requires nvidia-ml-py3, which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: thinc 6.12.1 has requirement msgpack<0.6.0,>=0.5.6, but you'll have msgpack 0.6.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: thinc 6.12.1 has requirement wrapt<1.11.0,>=1.10.0, but you'll have wrapt 1.11.2 which is incompatible.\u001b[0m\n",
      "Installing collected packages: wrapt, termcolor, tensorflow-gpu\n",
      "  Found existing installation: wrapt 1.10.11\n",
      "\u001b[31mERROR: Cannot uninstall 'wrapt'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\u001b[0m\n",
      "Requirement already satisfied: imutils in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (0.5.3)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (4.36.1)\n",
      "Requirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (5.1.2)\n",
      "Requirement already satisfied: h5py in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (2.9.0)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from h5py) (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.7 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from h5py) (1.17.2)\n",
      "Requirement already satisfied: tensorflow-hub in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (0.6.0)\n",
      "Requirement already satisfied: protobuf>=3.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow-hub) (3.9.2)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow-hub) (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow-hub) (1.17.2)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from protobuf>=3.4.0->tensorflow-hub) (41.4.0)\n"
     ]
    }
   ],
   "source": [
    "#%%capture\n",
    "# ^ hide the output\n",
    "\n",
    "#!conda update --all --yes\n",
    "#!conda install cudnn --yes\n",
    "\n",
    "!pip install --upgrade pip\n",
    "!pip install tensorflow-gpu\n",
    "!pip install imutils\n",
    "!pip install tqdm\n",
    "!pip install pyyaml h5py\n",
    "!pip install tensorflow-hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 Import the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-27430ddb4088>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import imageio\n",
    "import random\n",
    "import math\n",
    "import shutil\n",
    "import requests\n",
    "import skimage\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import tensorflow_hub as hub\n",
    "from collections import defaultdict\n",
    "\n",
    "# create a directory if it doesn't already exist\n",
    "make_dir = lambda path: os.path.exists(path) or os.makedirs(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.3 Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 224 #300 \n",
    "IMG_WIDTH = 224 # 300\n",
    "train_pct = 0.8\n",
    "batch_size = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [1] Get the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Create directories for the test and train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf data\n",
    "make_dir('data')\n",
    "make_dir('data/train')\n",
    "make_dir('data/test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Get the provided dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1 Download and unzip the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('train.zip'):\n",
    "    !curl https://ecs.victoria.ac.nz/foswiki/pub/Courses/COMP309_2019T2/Assignments/Train_data_2019.zip -o train.zip\n",
    "!unzip -oq train.zip -d data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2 Split the images using 309 as a seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(309)\n",
    "for label_dir in glob.glob('data/Train_data/*'):\n",
    "    label = label_dir.split('/')[-1]\n",
    "    make_dir(f'data/train/{label}')\n",
    "    make_dir(f'data/test/{label}')\n",
    "    \n",
    "    images = glob.glob(f'{label_dir}/*')\n",
    "    random.shuffle(images)\n",
    "    \n",
    "    split_index = math.floor(len(images) * train_pct)\n",
    "    for i, image in tqdm(enumerate(images), label):\n",
    "        train_or_test = 'train' if i < split_index else 'test'\n",
    "        new_path = image.replace('Train_data', train_or_test)\n",
    "        shutil.move(image, new_path)\n",
    "\n",
    "# clean-up the unzipped directory (will be empty)\n",
    "!rm -rf data/Train_data\n",
    "!rm -rf data/__MACOSX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Get images from ImageNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1 Fetch the ImageNet urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls imagenet_urls/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_urls_path = 'imagenet_urls/fall11_urls.txt'\n",
    "if not os.path.exists(imagenet_urls_path):\n",
    "    !rm -rf imagenet_urls \n",
    "    !mkdir imagenet_urls\n",
    "\n",
    "    # n.b. the main site is down: use a mirror\n",
    "    !wget https://v.im.cyut.edu.tw/ftp/18/imagenet_fall11_urls.tgz -O imagenet_urls/imagenet_fall11_urls.tgz\n",
    "    !tar -xvf imagenet_urls/imagenet_fall11_urls.tgz -C imagenet_urls\n",
    "\n",
    "raw_image_urls = list(open(imagenet_urls_path, encoding='ISO-8859-1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2 Find images for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_net_ids = {\n",
    "    'strawberry': ['n07745940'],\n",
    "    'cherry': ['n07757132', 'n07757312', 'n07757874', 'n07757990'],\n",
    "    'tomato': ['n07734292', 'n07734292']\n",
    "}\n",
    "\n",
    "image_urls_by_class = defaultdict(list)\n",
    "for line in tqdm(raw_image_urls):\n",
    "    image_id = line.split('\\t')[0].split('_')[0]\n",
    "    image_url = line.split('\\t')[1].strip()\n",
    "    \n",
    "    for class_name, ids in word_net_ids.items():\n",
    "        if image_id in ids:\n",
    "            image_urls_by_class[class_name] += [image_url]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.3 Download applicable images from ImageNet\n",
    "Note: images from Flickr are filtered out as they may be in the evaluation data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    dead_images\n",
    "except:\n",
    "    dead_images = [] # don't retry these again this session\n",
    "    \n",
    "for class_name, urls in image_urls_by_class.items():\n",
    "    # filter out images from flickr\n",
    "    not_flickr = [url for url in urls if 'flickr' not in url]\n",
    "    for i, url in tqdm(list(enumerate(not_flickr)), class_name):\n",
    "        extension = url.split('.')[-1].lower()\n",
    "        if extension not in ['jpg', 'jpeg', 'png']: continue\n",
    "        \n",
    "        out_image_path = f'data/train/{class_name}/image_net_{i:03}.jpg'\n",
    "        if os.path.exists(out_image_path) or url in dead_images:\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url, timeout=(2, 5), allow_redirects=False)\n",
    "            assert response.status_code == 200\n",
    "        except (\n",
    "            AssertionError, # status code wasn't 200\n",
    "            requests.exceptions.ReadTimeout,\n",
    "            requests.exceptions.ConnectionError,\n",
    "            requests.exceptions.Timeout\n",
    "        ): # can't download image\n",
    "            dead_images += [url]\n",
    "            continue\n",
    "            \n",
    "        temp_file_name = f'temp.{extension}'\n",
    "        open(temp_file_name, 'wb').write(response.content)\n",
    "        \n",
    "        try:\n",
    "            image = imageio.imread(temp_file_name)\n",
    "            if image.shape[-1] == 4:\n",
    "                image = skimage.color.rgba2rgb(image)\n",
    "            \n",
    "            if image.dtype != np.uint8:\n",
    "                image = (image * 255).astype(np.uint8)\n",
    "            imageio.imwrite(out_image_path, image)\n",
    "        except ValueError: # isn't a valid image\n",
    "            dead_images += [url]\n",
    "            continue\n",
    "        finally:\n",
    "            os.remove(temp_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Process images from Google Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is manually uploaded\n",
    "!unzip -oq google_images.zip\n",
    "\n",
    "all_images = enumerate(glob.glob('google_images/*/*'))\n",
    "for i, image_path in tqdm(list(all_images)):\n",
    "    class_name = image_path.split('/')[-2].replace('cherry_tomato', 'tomato')\n",
    "    \n",
    "    image = imageio.imread(image_path)\n",
    "    imageio.imwrite(f'data/train/{class_name}/google_images_{i:04}.jpg', image)\n",
    "    \n",
    "!rm -rf google_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_name in ['tomato', 'cherry', 'strawberry']:\n",
    "    print(class_name, len(glob.glob(f'data/train/{class_name}/*')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [2] Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Specify the data augmentation to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = dict(\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=35,\n",
    "    zoom_range=0.25,\n",
    "    width_shift_range=0.15,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=25,\n",
    "    brightness_range=[0.75, 1.25],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Build the ImageDataGenerators\n",
    "Note: the test data isn't augmented here, but TTA is later implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train:', end=' ')\n",
    "train_data_gen = ImageDataGenerator(rescale=1.0/255, **data_augmentation).flow_from_directory(\n",
    "    batch_size=batch_size,\n",
    "    directory='data/train',\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    ")\n",
    "\n",
    "print('Test:', end=' ')\n",
    "test_data_gen = ImageDataGenerator(rescale=1.0/255).flow_from_directory(\n",
    "    batch_size=batch_size,\n",
    "    directory='data/test',\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Visualise the data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(4, 5)\n",
    "\n",
    "for image in range(axes.shape[0]):\n",
    "    for example in tqdm(range(axes.shape[1])):\n",
    "        axes[image,example].imshow(train_data_gen[0][0][image])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [3] Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Create a transfer learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_histories = []\n",
    "\n",
    "# Create the base model from the pre-trained model MobileNet V2\n",
    "base_model = tf.keras.applications.MobileNetV2(\n",
    "    input_shape=(IMG_WIDTH, IMG_HEIGHT, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "base_model.trainable = False # freeze the pre-trained bit\n",
    "\n",
    "# wrap the model in a sequential model\n",
    "model = tf.keras.Sequential([\n",
    "    base_model,\n",
    "    tf.keras.layers.AveragePooling2D(),\n",
    "    Flatten(),\n",
    "    Dropout(0.25),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Train the trail of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "r = model.fit_generator(\n",
    "    train_data_gen,\n",
    "    validation_data=test_data_gen,\n",
    "    epochs=15,\n",
    ")\n",
    "\n",
    "train_histories.append(r.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Unfreeze some of the pre-trained model and continue training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:100]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.RMSprop(lr=1e-5),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "r = model.fit_generator(\n",
    "    train_data_gen,\n",
    "    validation_data=test_data_gen,\n",
    "    initial_epoch=15,\n",
    "    epochs=30,\n",
    ")\n",
    "\n",
    "train_histories.append(r.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Unfreeze more of the pre-trained model and continue training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:50]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.RMSprop(lr=3e-6),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "r = model.fit_generator(\n",
    "    train_data_gen,\n",
    "    validation_data=test_data_gen,\n",
    "    initial_epoch=15,\n",
    "    epochs=30,\n",
    ")\n",
    "\n",
    "train_histories.append(r.history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
